{
    "@graph": [
        {
            "@id": "gnd:115233865X",
            "sameAs": "Sevgi, Meltem"
        },
        {
            "@id": "gnd:128567961",
            "sameAs": "Donner, Tobias H."
        },
        {
            "@id": "gnd:143795244",
            "sameAs": "Haueisen, Jens"
        },
        {
            "@id": "gnd:2125187-3",
            "sameAs": "Technische Universität Ilmenau"
        },
        {
            "@id": "gnd:4047686-8",
            "sameAs": "Psychische Störung"
        },
        {
            "@id": "gnd:4120666-6",
            "sameAs": "Lernendes System"
        },
        {
            "@id": "gnd:4121849-8",
            "sameAs": "Verhaltensmuster"
        },
        {
            "@id": "gnd:4144220-9",
            "sameAs": "Bayes-Entscheidungstheorie"
        },
        {
            "@id": "gnd:4172613-3",
            "sameAs": "Operante Konditionierung"
        },
        {
            "@id": "gnd:4366912-8",
            "sameAs": "Evolutionärer Algorithmus"
        },
        {
            "@id": "gnd:7618675-1",
            "sameAs": "Funktionelle Kernspintomografie"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A1013873637",
            "@type": "bibo:Thesis",
            "P1053": "1 Online-Ressource (xvi, 114 Seiten)",
            "http://purl.org/dc/elements/1.1/contributor": "Moran, Rosalyn",
            "description": "Diagramme, Illustrationen (teilweise farbig)",
            "identifier": [
                "(firstid)GBV:1013873637",
                "(ppn)1013873637"
            ],
            "publisher": "Universitätsbibliothek",
            "http://purl.org/dc/elements/1.1/subject": [
                "(classificationName=linseach:mapping)inf",
                "(classificationName=ddc-dbn)004",
                "(classificationName=ddc)006.31"
            ],
            "title": "Mechanistic models of reward based learning and decision making for clinically motivated problems",
            "abstract": "Mechanistische Modelle für Lernen und zur Entscheidungsfindung können helfen, spezifische Hypothesen über beobachtetes Verhalten und dessen Etablierung in Gehirn zu testen. Die hier vorliegende Arbeit bietet einen Ansatz, um computergestützte Modelle zum Verstärkungslernen (Reinforcement Learning) und Bayes&apos;sche Lernalgorithmen zu integrieren, und um klinisch motivierte Probleme zu adressieren. Die so entstandenen Modelle wurden anhand von funktionelle Magnetresonanztomographie (fMRT) gemeinsam mit Verhaltens- und Konnektivitätsmodellen evaluiert. In dieser Arbeit werden vor allem Algorithmen zum Verstärkungslernen betrachtet, typischerweise die im bildgebenden und in psychologischen Studien zur Anwendung kommen. Eine Bewertung der Algorithmen erfolgte mithilfe von Simulationen, um somit das Verhalten von virtuellen Agenten bei unterschiedlichen Modellparametern und Strategien zu verstehen. Später wurden die generierten Modelle an einem empirischen Datensatz getestet, wobei das beste Modell zur Auswertung der fMRI Daten an ein lineares Modell übergeben wurde. Solche Modelle konnten Unterschiede in der Funktion von dopaminergen Gehirnregionen und dem damit assoziierten Verhalten zwischen Individuen mit unterschiedlicher genetische Disposition zeigen. Weiterhin wurde untersucht, ob die Einbeziehung von Lernalgorithmen in effektive Konnektivitätsmodelle als komplementäre Grundlage für die weitere Erforschung von veränderten Netzwerkdynamiken im menschlichen Gehirn dienen könnte. Dazu wurden bilineare und nicht-lineare dynamisch kausale Modelle verschiedener Hirnregionen, welche in Belohnungslernen und Vorhersagefehlerprozessen beteiligt sind, erstellt. In einer Erweiterung, wurden hierarchische Bayes&apos;sche Modelle betrachtet, welche das Lernverhalten eines virtuellen Agenten in einer komplexen und unbeständigen Umgebung modellieren. Ein paralleler Lernansatz wurde zum Lernen und Kombinieren multipler Hinweisreize entwickelt, indem hierarchische Gauss&apos;schen Filter mit präzisionsgewichteten Antwortmodellen gepaart wurden. Simulationen von Parameterschätzungen deuten darauf hin, dass dieser Ansatz zum Lernen und Kombinieren verschiedener Informationsquellen genutzt werden kann. Das vorgeschlagene Modell wurde auf Grundlage empirische Daten überprüft und mit alternativen Modellen verglichen, wie beispielsweise mit dem optimalen Bayes&apos;schen Agenten. Letztlich hat uns diese Methode ermöglicht, individuelle Subprozesse zu identifizieren, die am Lernen von sozialen Hinweisreizen beteiligt sind und die mit unterschiedlichen Ausprägungen vom autistischen Züge variieren. Darüber hinaus postulieren wir, dass der hier vorgestellte experimentelle und modellierende Ansatz zu einer mechanistischen Beschreibung von unterschiedlichen psychiatrischen Störungen beitragen kann.",
            "contributor": [
                "gnd:143795244",
                "gnd:128567961"
            ],
            "dcterms:contributor": "Technische Informationsbibliothek (TIB)",
            "creator": [
                "gnd:2125187-3",
                "gnd:115233865X"
            ],
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2017",
            "language": "http://id.loc.gov/vocabulary/iso639-1/en",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "subject": [
                "gnd:4120666-6",
                "gnd:4047686-8",
                "gnd:4172613-3",
                "gnd:7618675-1",
                "gnd:4144220-9",
                "gnd:4366912-8",
                "gnd:4121849-8"
            ],
            "P60163": "Ilmenau"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "subject": {
            "@id": "http://purl.org/dc/terms/subject",
            "@type": "@id"
        },
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "contributor": {
            "@id": "http://purl.org/dc/terms/contributor",
            "@type": "@id"
        },
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "license": "http://purl.org/dc/terms/license",
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "description": "http://purl.org/dc/elements/1.1/description",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "title": "http://purl.org/dc/elements/1.1/title",
        "abstract": "http://purl.org/dc/terms/abstract",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "issued": "http://purl.org/dc/terms/issued",
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}