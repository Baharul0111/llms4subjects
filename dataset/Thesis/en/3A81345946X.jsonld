{
    "@graph": [
        {
            "@id": "gnd:1064956165",
            "sameAs": "Rößing, Christoph"
        },
        {
            "@id": "gnd:4145159-4",
            "sameAs": "Bewegungssehen"
        },
        {
            "@id": "gnd:7684412-2",
            "sameAs": "Bewegungsunschärfe"
        },
        {
            "@id": "https://www.tib.eu/de/suchen/id/TIBKAT%3A81345946X",
            "@type": "bibo:Thesis",
            "P1053": "Online-Ressource",
            "identifier": [
                "(ppn)81345946X",
                "(firstid)DNB:1064002587",
                "(isbn13)9783941543157"
            ],
            "publisher": "Universität Ulm. Fakultät für Ingenieurwissenschaften und Informatik",
            "subject": [
                "Bewegungsunschärfe",
                "(classificationName=ddc-dbn)610",
                "(classificationName=ddc)000",
                "(classificationName=linseach:mapping)meda",
                "Depth perception",
                "Bewegungssehen",
                "Motion perception"
            ],
            "title": "Video and image manipulation for enhanced perception",
            "abstract": "The present thesis proposes novel methods for the perceptually motivated real-time rendering of pictorial depth and motion cues in still images and video sequences. Therefore, the human visual system is evaluated from a psychological and physiological viewpoint. The proposed novel rendering techniques address these specific neuronal structures to subconsciously convey supplemental scene information to the viewer. The novel monocular depth cue enhancement pipeline amplifies pictorial cues to increase the perceived spatiality in images. It utilizes a stereo algorithm to generate an initial supplemental disparity map which is refined and subsequently used to render artificial defocus blur, distance-adaptive local contrast enhancement, depth controlled desaturation, and artificial drop shadows. Merging these visualizations yields an immersive depth sensation. The novel motion depiction pipeline computes the optical flow with the novel À-trous Flow method. Subsequently, a rendering stage approximates natural motion blur, stroboscopic exposure or comic-like speed lines. As result, trajectory and dynamics inside the scene can be easily assessed. The synergies created by the combined computation of scene reconstruction and visualization with real-time capabable a-trous wavelets enable video streaming applications. The third pipeline is specialized on monocular highway traffic scene reconstruction and the enrichment of a rear-view camera videos. In order to support the driver in his scene assessment, the gathered information is conveyed via artificial motion or defocus blur and a color-coded risk potential rendering. All suggested methods are discussed from a perceptual viewpoint. Furthermore, two conducted perceptual studies confirm that the proposed renderings guide visual attention towards specific image areas and convey rough velocity information to the viewer.",
            "contributor": "Technische Informationsbibliothek (TIB)",
            "creator": "gnd:1064956165",
            "isPartOf": "(collectioncode)GBV-ODiss",
            "issued": "2014",
            "language": "http://id.loc.gov/vocabulary/iso639-1/de",
            "license": "open access",
            "medium": "rda:termList/RDACarrierType/1018",
            "dcterms:subject": [
                {
                    "@id": "gnd:4145159-4"
                },
                {
                    "@id": "gnd:7684412-2"
                }
            ],
            "volume": "12",
            "P30128": "Schriftenreihe des Instituts für Mess-, Regel- und Mikrotechnik",
            "P60163": "Ulm"
        }
    ],
    "@id": "urn:x-arq:DefaultGraphNode",
    "@context": {
        "sameAs": "http://www.w3.org/2002/07/owl#sameAs",
        "subject": "http://purl.org/dc/elements/1.1/subject",
        "P60163": "http://www.rdaregistry.info/Elements/u/#P60163",
        "contributor": "http://purl.org/dc/terms/contributor",
        "issued": "http://purl.org/dc/terms/issued",
        "medium": {
            "@id": "http://purl.org/dc/terms/medium",
            "@type": "@id"
        },
        "identifier": "http://purl.org/dc/elements/1.1/identifier",
        "creator": {
            "@id": "http://purl.org/dc/terms/creator",
            "@type": "@id"
        },
        "volume": "http://purl.org/ontology/bibo/volume",
        "title": "http://purl.org/dc/elements/1.1/title",
        "abstract": "http://purl.org/dc/terms/abstract",
        "isPartOf": "http://purl.org/dc/terms/isPartOf",
        "P30128": "http://www.rdaregistry.info/Elements/m/#P30128",
        "P1053": "http://iflastandards.info/ns/isbd/elements/P1053",
        "publisher": "http://purl.org/dc/elements/1.1/publisher",
        "license": "http://purl.org/dc/terms/license",
        "language": {
            "@id": "http://purl.org/dc/terms/language",
            "@type": "@id"
        },
        "umbel": "http://umbel.org/umbel#",
        "rdau": "http://www.rdaregistry.info/Elements/u/#",
        "owl": "http://www.w3.org/2002/07/owl#",
        "dcterms": "http://purl.org/dc/terms/",
        "bibo": "http://purl.org/ontology/bibo/",
        "rdam": "http://www.rdaregistry.info/Elements/m/#",
        "gnd": "http://d-nb.info/gnd/",
        "isbd": "http://iflastandards.info/ns/isbd/elements/",
        "rda": "http://rdvocab.info/",
        "doi": "https://doi.org/"
    }
}